{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NLPdataEx3&4-data_in.txt','r') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there, how are you? Weather is awesome. Its raining here now.\\nHello Mr. Raja, how are you? Weather is awesome. Its raining here now.\\nHello Mr. Raja, how are you. Weather is bad. Its heavily raining here now.\\nNLP is great technique. It is nice to learn this technique.\\nAI is making difference in this world now.  It would be helpful for betterment of human life. We need to make advantage of that.\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello there, how are you?',\n",
       " 'Weather is awesome.',\n",
       " 'Its raining here now.',\n",
       " 'Hello Mr. Raja, how are you?',\n",
       " 'Weather is awesome.',\n",
       " 'Its raining here now.',\n",
       " 'Hello Mr. Raja, how are you.',\n",
       " 'Weather is bad.',\n",
       " 'Its heavily raining here now.',\n",
       " 'NLP is great technique.',\n",
       " 'It is nice to learn this technique.',\n",
       " 'AI is making difference in this world now.',\n",
       " 'It would be helpful for betterment of human life.',\n",
       " 'We need to make advantage of that.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [sentence for sentence in nltk.sent_tokenize(data)]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize Words in sentence                        :['Hello', 'there', 'how', 'are', 'you']\n",
      "Tokenize words in sentence after stopwords removal:['Hello']\n",
      "Stemming of words in sentence                     :['hello', 'there', 'how', 'are', 'you']\n",
      "Lemmatization of words in sentence                :['hello', 'there', ' ', 'how', 'be', '-PRON-']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['Weather', 'is', 'awesome']\n",
      "Tokenize words in sentence after stopwords removal:['Weather', 'awesome']\n",
      "Stemming of words in sentence                     :['weather', 'is', 'awesom']\n",
      "Lemmatization of words in sentence                :['weather', 'be', 'awesome']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['Its', 'raining', 'here', 'now']\n",
      "Tokenize words in sentence after stopwords removal:['Its', 'raining']\n",
      "Stemming of words in sentence                     :['it', 'rain', 'here', 'now']\n",
      "Lemmatization of words in sentence                :['-PRON-', 'rain', 'here', 'now']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['Hello', 'Mr', 'Raja', 'how', 'are', 'you']\n",
      "Tokenize words in sentence after stopwords removal:['Hello', 'Mr', 'Raja']\n",
      "Stemming of words in sentence                     :['hello', 'Mr', 'raja', 'how', 'are', 'you']\n",
      "Lemmatization of words in sentence                :['hello', 'Mr', ' ', 'Raja', ' ', 'how', 'be', '-PRON-']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['Weather', 'is', 'awesome']\n",
      "Tokenize words in sentence after stopwords removal:['Weather', 'awesome']\n",
      "Stemming of words in sentence                     :['weather', 'is', 'awesom']\n",
      "Lemmatization of words in sentence                :['weather', 'be', 'awesome']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['Its', 'raining', 'here', 'now']\n",
      "Tokenize words in sentence after stopwords removal:['Its', 'raining']\n",
      "Stemming of words in sentence                     :['it', 'rain', 'here', 'now']\n",
      "Lemmatization of words in sentence                :['-PRON-', 'rain', 'here', 'now']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['Hello', 'Mr', 'Raja', 'how', 'are', 'you']\n",
      "Tokenize words in sentence after stopwords removal:['Hello', 'Mr', 'Raja']\n",
      "Stemming of words in sentence                     :['hello', 'Mr', 'raja', 'how', 'are', 'you']\n",
      "Lemmatization of words in sentence                :['hello', 'Mr', ' ', 'Raja', ' ', 'how', 'be', '-PRON-']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['Weather', 'is', 'bad']\n",
      "Tokenize words in sentence after stopwords removal:['Weather', 'bad']\n",
      "Stemming of words in sentence                     :['weather', 'is', 'bad']\n",
      "Lemmatization of words in sentence                :['weather', 'be', 'bad']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['Its', 'heavily', 'raining', 'here', 'now']\n",
      "Tokenize words in sentence after stopwords removal:['Its', 'heavily', 'raining']\n",
      "Stemming of words in sentence                     :['it', 'heavili', 'rain', 'here', 'now']\n",
      "Lemmatization of words in sentence                :['-PRON-', 'heavily', 'rain', 'here', 'now']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['NLP', 'is', 'great', 'technique']\n",
      "Tokenize words in sentence after stopwords removal:['NLP', 'great', 'technique']\n",
      "Stemming of words in sentence                     :['nlp', 'is', 'great', 'techniqu']\n",
      "Lemmatization of words in sentence                :['NLP', 'be', 'great', 'technique']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['It', 'is', 'nice', 'to', 'learn', 'this', 'technique']\n",
      "Tokenize words in sentence after stopwords removal:['It', 'nice', 'learn', 'technique']\n",
      "Stemming of words in sentence                     :['It', 'is', 'nice', 'to', 'learn', 'thi', 'techniqu']\n",
      "Lemmatization of words in sentence                :['-PRON-', 'be', 'nice', 'to', 'learn', 'this', 'technique']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['AI', 'is', 'making', 'difference', 'in', 'this', 'world', 'now']\n",
      "Tokenize words in sentence after stopwords removal:['AI', 'making', 'difference', 'world']\n",
      "Stemming of words in sentence                     :['AI', 'is', 'make', 'differ', 'in', 'thi', 'world', 'now']\n",
      "Lemmatization of words in sentence                :['AI', 'be', 'make', 'difference', 'in', 'this', 'world', 'now']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['It', 'would', 'be', 'helpful', 'for', 'betterment', 'of', 'human', 'life']\n",
      "Tokenize words in sentence after stopwords removal:['It', 'would', 'helpful', 'betterment', 'human', 'life']\n",
      "Stemming of words in sentence                     :['It', 'would', 'be', 'help', 'for', 'better', 'of', 'human', 'life']\n",
      "Lemmatization of words in sentence                :['-PRON-', 'would', 'be', 'helpful', 'for', 'betterment', 'of', 'human', 'life']\n",
      "\n",
      "\n",
      "Tokenize Words in sentence                        :['We', 'need', 'to', 'make', 'advantage', 'of', 'that']\n",
      "Tokenize words in sentence after stopwords removal:['We', 'need', 'make', 'advantage']\n",
      "Stemming of words in sentence                     :['We', 'need', 'to', 'make', 'advantag', 'of', 'that']\n",
      "Lemmatization of words in sentence                :['-PRON-', 'need', 'to', 'make', 'advantage', 'of', 'that']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_stemmer = PorterStemmer()\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = re.sub(r'[.\\?,]',' ',sentences[i])\n",
    "    sentences[i] = re.sub(r's\\+',' ',sentences[i])\n",
    "    #sentences[i] = sentences[i].lower()\n",
    "    word_token = nltk.word_tokenize(sentences[i])\n",
    "    filtered_sent = [w for w in word_token if w not in stop_words]\n",
    "    stem_word = [p_stemmer.stem(word) for word in word_token]\n",
    "    #lemma_sent = nlp(sentences[i])\n",
    "    lemma_word = [token.lemma_ for token in nlp(sentences[i])]\n",
    "    print(f\"Tokenize Words in sentence                        :{word_token}\")\n",
    "    print(f\"Tokenize words in sentence after stopwords removal:{filtered_sent}\")\n",
    "    print(f\"Stemming of words in sentence                     :{stem_word}\")\n",
    "    print(f\"Lemmatization of words in sentence                :{lemma_word}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
